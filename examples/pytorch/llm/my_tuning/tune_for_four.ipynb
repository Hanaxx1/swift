{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO:swift] Setting torch_dtype: torch.bfloat16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:06<00:00,  2.16s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import torch\n",
    "from transformers import LlamaForCausalLM, LlamaTokenizer\n",
    "from peft import PeftModel,PeftConfig\n",
    "import re\n",
    "import json\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import PeftModel, PeftConfig\n",
    "import torch\n",
    "from swift.llm import (\n",
    "    get_model_tokenizer, get_template, inference, ModelType, get_default_template_type,\n",
    ")\n",
    "\n",
    "model_type1 = ModelType.mistral_7b_chat_v2\n",
    "template_type1 = get_default_template_type(model_type1)\n",
    "model_mistral, tokenizer_mistral = get_model_tokenizer(model_type1, model_kwargs={'device_map': 'auto'}, model_dir=\"/home/css/models/Mistral-7B-Instruct-v0.2\")\n",
    "\n",
    "import json\n",
    "def validate_format(input_string):\n",
    "    pattern = re.compile(r'^\\d{4}-\\d{2}$')\n",
    "    return bool(pattern.match(input_string))\n",
    "\n",
    "def sql_json_to_alpaca_json(json_path, new_data_list):\n",
    "    # 读取已有的 JSON 数据\n",
    "    try:\n",
    "        with open(json_path, \"r\") as file:\n",
    "            json_data_list = json.load(file)\n",
    "    except FileNotFoundError:\n",
    "        # 如果文件不存在，创建一个空的列表\n",
    "        json_data_list = []\n",
    "\n",
    "    # 将新数据追加到列表\n",
    "    json_data_list.extend(new_data_list)\n",
    "\n",
    "    # 将更新后的列表写回 JSON 文件\n",
    "    with open(json_path, \"w\") as json_file:\n",
    "        json.dump(json_data_list, json_file, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10215\n",
      "10215\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import re\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#推理结果\n",
    "tune_file_path = '/home/qiuyang/workplace/swift/examples/pytorch/llm/my_tuning/data/mistral_list2.json'\n",
    "# 打开文件并加载JSON数据\n",
    "with open(tune_file_path, 'r') as file:\n",
    "    tune_result_list = json.load(file)\n",
    "\n",
    "print(len(tune_result_list))\n",
    "\n",
    "# 打开JSON文件\n",
    "i = 0\n",
    "new_data = [] \n",
    "with open('/home/qiuyang/workplace/swift/examples/pytorch/llm/my_tuning/data/c4_data2.json', 'r') as file:\n",
    "    # 逐行读取文件内容\n",
    "    for line in file:\n",
    "        # 解析JSON数据\n",
    "        data = json.loads(line)\n",
    "        content = data['content']\n",
    "        if len(tokenizer_mistral.tokenize(data['content'])) <3500:\n",
    "            tune_result = tune_result_list[i]\n",
    "            i = i + 1\n",
    "            tune_result = str(tune_result)\n",
    "            result = tune_result[1:-1].split(',')\n",
    "\n",
    "            if len(result) == 3:\n",
    "                output = \"[No,UNKNOWN,UNKNOWN,UNKNOWN]\"\n",
    "                new_json_data = {\n",
    "                    'instruction': '''Whether anyone in the information was transferred between countries in text?if so,from which country to which country?What year and month did the transfer take place?only give the starting point and destination example [Yes or No,starting point,destination,year-month],just country name.''',\n",
    "                    'input': content,\n",
    "                    'output': output\n",
    "                }\n",
    "                new_data.append(new_json_data)\n",
    "            elif len(result) == 4:\n",
    "                if result[0] == \"Yes\" and validate_format(result[3]):\n",
    "                    output = tune_result\n",
    "                    new_json_data = {\n",
    "                    'instruction': '''Whether anyone in the information was transferred between countries in text?if so,from which country to which country?What year and month did the transfer take place?only give the starting point and destination example [Yes or No,starting point,destination,year-month],just country name.''',\n",
    "                    'input': content,\n",
    "                    'output': output\n",
    "                }\n",
    "                new_data.append(new_json_data)\n",
    "        \n",
    "print(i)\n",
    "sql_json_to_alpaca_json('/home/qiuyang/llama-recipes/src/llama_recipes/lla_datasets/alpaca_data_siyuanzu_process.json',new_data_list=new_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qiuyang/miniconda3/envs/llama/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-04-19 12:33:18,477 - modelscope - INFO - PyTorch version 2.1.0 Found.\n",
      "2024-04-19 12:33:18,480 - modelscope - INFO - Loading ast index from /home/qiuyang/.cache/modelscope/ast_indexer\n",
      "2024-04-19 12:33:18,508 - modelscope - INFO - No valid ast index found from /home/qiuyang/.cache/modelscope/ast_indexer, generating ast index from prebuilt!\n",
      "2024-04-19 12:33:18,547 - modelscope - INFO - Loading done! Current index file version is 1.10.0, with md5 f2afa420ba88f7e5b952e2c45c555d34 and a total number of 946 components indexed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import torch\n",
    "from transformers import LlamaForCausalLM, LlamaTokenizer\n",
    "from peft import PeftModel,PeftConfig\n",
    "import re\n",
    "import json\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import PeftModel, PeftConfig\n",
    "import torch\n",
    "from swift.llm import (\n",
    "    get_model_tokenizer, get_template, inference, ModelType, get_default_template_type,\n",
    ")\n",
    "\n",
    "# model_type1 = ModelType.mistral_7b_instruct_v2\n",
    "# template_type1 = get_default_template_type(model_type1)\n",
    "# model_mistral, tokenizer_mistral = get_model_tokenizer(model_type1, model_kwargs={'device_map': 'auto'}, model_dir=\"/home/css/models/Mistral-7B-Instruct-v0.2\")\n",
    "\n",
    "import json\n",
    "def validate_format(input_string):\n",
    "    pattern = re.compile(r'^\\d{4}-\\d{2}$')\n",
    "    return bool(pattern.match(input_string))\n",
    "\n",
    "\n",
    "print(validate_format(\"[No,UNKNOWN,UNKNOWN,UNKNOWN]\"))\n",
    "\n",
    "def sql_json_to_alpaca_json(json_path, new_data_list):\n",
    "    # 读取已有的 JSON 数据\n",
    "    try:\n",
    "        with open(json_path, \"r\") as file:\n",
    "            json_data_list = json.load(file)\n",
    "    except FileNotFoundError:\n",
    "        # 如果文件不存在，创建一个空的列表\n",
    "        json_data_list = []\n",
    "\n",
    "    # 将新数据追加到列表\n",
    "    json_data_list.extend(new_data_list)\n",
    "\n",
    "    # 将更新后的列表写回 JSON 文件\n",
    "    with open(json_path, \"a\") as json_file:\n",
    "        json.dump(json_data_list, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12242\n",
      "12242\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import re\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#推理结果\n",
    "tune_file_path = '/home/qiuyang/workplace/swift/examples/pytorch/llm/my_data/data_sanyuanzu/mistral_list3.json'\n",
    "# 打开文件并加载JSON数据\n",
    "with open(tune_file_path, 'r') as file:\n",
    "    tune_result_list = json.load(file)\n",
    "\n",
    "print(len(tune_result_list))\n",
    "\n",
    "# 打开JSON文件\n",
    "i = 0\n",
    "\n",
    "count = 0\n",
    "new_data = [] \n",
    "with open('/home/qiuyang/workplace/swift/examples/pytorch/llm/my_data/data/c4_data_length_3500/c4_data3_3500.json', 'r') as file:\n",
    "    # 逐行读取文件内容\n",
    "    for line in file:\n",
    "        # 解析JSON数据\n",
    "        data = json.loads(line)\n",
    "        content = data['content']\n",
    "\n",
    "        tune_result = tune_result_list[i]\n",
    "        i = i + 1\n",
    "        tune_result = str(tune_result)\n",
    "        result = tune_result[1:-1].split(',')\n",
    "\n",
    "        if len(result) == 3:\n",
    "\n",
    "            if result[0] == \"Yes\":\n",
    "                output = tune_result\n",
    "                # output = \"[No,UNKNOWN,UNKNOWN,UNKNOWN]\"\n",
    "                new_json_data = {\n",
    "                    'instruction': '''Whether anyone in the information was transferred between countries in text?if so,from which country to which country?only give the starting point and destination example [Yes or No,starting point,destination],just country name.''',\n",
    "                    'input': content,\n",
    "                    'output': output\n",
    "                }\n",
    "                new_data.append(new_json_data)\n",
    "            else:\n",
    "                count = count + 1\n",
    "                if count == 4:\n",
    "                    count = 0\n",
    "                    output = \"[No,UNKNOWN,UNKNOWN]\"\n",
    "                    new_json_data = {\n",
    "                        'instruction': '''Whether anyone in the information was transferred between countries in text?if so,from which country to which country?only give the starting point and destination example [Yes or No,starting point,destination],just country name.''',\n",
    "                        'input': content,\n",
    "                        'output': output\n",
    "                    }\n",
    "                    new_data.append(new_json_data)\n",
    "                    \n",
    "        # elif len(result) == 4:\n",
    "        #     if result[0] == \"Yes\" and validate_format(result[3]):\n",
    "        #         output = tune_result\n",
    "        #         new_json_data = {\n",
    "        #         'instruction': '''Whether anyone in the information was transferred between countries in text?if so,from which country to which country?What year and month did the transfer take place?only give the starting point and destination example [Yes or No,starting point,destination,year-month],just country name.''',\n",
    "        #         'input': content,\n",
    "        #         'output': output\n",
    "        #     }\n",
    "        #     new_data.append(new_json_data)\n",
    "        \n",
    "print(i)\n",
    "sql_json_to_alpaca_json('/home/qiuyang/llama-recipes/src/llama_recipes/lla_datasets/alpaca_data_sanyuanzu_process1.json',new_data_list=new_data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
